import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix

# -----------------------------------------------------------------------------
# å…¸å‹ç”¨é€”ï¼šæœºå™¨å­¦ä¹ å¿«é€ŸåŸå‹ (ML Prototyping)
# æ ¸å¿ƒç‰¹è‰²ï¼šScript-to-App æ¨¡å¼ï¼Œæ— éœ€æ‡‚å‰ç«¯å³å¯å¿«é€Ÿå°† Python è„šæœ¬è½¬åŒ–ä¸ºäº¤äº’å¼åº”ç”¨
# -----------------------------------------------------------------------------

st.set_page_config(page_title="ML æ¨¡å‹æ¼”ç»ƒåœº", page_icon="ğŸ¤–", layout="wide")

st.title("ğŸ¤– æœºå™¨å­¦ä¹ æ¨¡å‹æ¼”ç»ƒåœº")
st.markdown("""
> **Streamlit ç‰¹è‰²å±•ç¤º**ï¼š
> è¿™æ˜¯ä¸€ä¸ªå…¸å‹çš„ ML åŸå‹åº”ç”¨ã€‚é€šè¿‡ä¾§è¾¹æ è°ƒæ•´è¶…å‚æ•°ï¼Œå®æ—¶è§¦å‘æ¨¡å‹è®­ç»ƒå¹¶å¯è§†åŒ–ç»“æœã€‚
> è¿™ç§"æ‰€è§å³æ‰€å¾—"çš„å¼€å‘æ¨¡å¼æ˜¯ Streamlit æœ€å¤§çš„ä¼˜åŠ¿ã€‚
""")

# 1. æ•°æ®åŠ è½½
with st.sidebar:
    st.header("1. æ¨¡å‹é…ç½®")
    st.info("ä½¿ç”¨ç»å…¸çš„ Iris é¸¢å°¾èŠ±æ•°æ®é›†")
    
    n_estimators = st.slider("å†³ç­–æ ‘æ•°é‡ (n_estimators)", 10, 200, 100, 10)
    max_depth = st.slider("æœ€å¤§æ·±åº¦ (max_depth)", 1, 20, 5)
    criterion = st.selectbox("åˆ†è£‚æ ‡å‡†", ["gini", "entropy"])

# åŠ è½½æ•°æ®
@st.cache_data
def load_data():
    df = sns.load_dataset('iris')
    return df

df = load_data()

# 2. é¡µé¢å¸ƒå±€ - æ•°æ®æ¦‚è§ˆ
col1, col2 = st.columns([1, 2])

with col1:
    st.subheader("åŸå§‹æ•°æ®")
    st.dataframe(df.head(10), use_container_width=True)
    st.caption(f"æ€»æ ·æœ¬æ•°: {len(df)}")

with col2:
    st.subheader("ç‰¹å¾åˆ†å¸ƒ")
    fig, ax = plt.subplots(figsize=(10, 4))
    sns.scatterplot(data=df, x='sepal_length', y='sepal_width', hue='species', ax=ax)
    st.pyplot(fig)

# 3. æ¨¡å‹è®­ç»ƒ
st.divider()
st.subheader("2. æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°")

# å‡†å¤‡æ•°æ®
X = df.drop('species', axis=1)
y = df['species']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# è®­ç»ƒ
clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, criterion=criterion)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

# æŒ‡æ ‡
acc = accuracy_score(y_test, y_pred)

# æ˜¾ç¤ºæŒ‡æ ‡å¡ç‰‡
m1, m2, m3 = st.columns(3)
m1.metric("æ¨¡å‹å‡†ç¡®ç‡ (Accuracy)", f"{acc:.2%}", delta=f"{acc-0.9:.2%}")
m2.metric("è®­ç»ƒæ ·æœ¬æ•°", len(X_train))
m3.metric("æµ‹è¯•æ ·æœ¬æ•°", len(X_test))

# 4. ç»“æœå¯è§†åŒ–
c1, c2 = st.columns(2)

with c1:
    st.markdown("#### æ··æ·†çŸ©é˜µ")
    cm = confusion_matrix(y_test, y_pred)
    fig_cm, ax_cm = plt.subplots()
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax_cm)
    st.pyplot(fig_cm)

with c2:
    st.markdown("#### ç‰¹å¾é‡è¦æ€§")
    feat_importances = pd.Series(clf.feature_importances_, index=X.columns)
    st.bar_chart(feat_importances)

st.success("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼å°è¯•è°ƒæ•´ä¾§è¾¹æ å‚æ•°æ¥ä¼˜åŒ–æ¨¡å‹ã€‚")
